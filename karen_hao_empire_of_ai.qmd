---
title: Karen Hao- Empire of AI
date: 2025-06-04 10:30:17
---

From **democracynow.org**:

[Empire of AI”: Karen Hao on How AI Is Threatening Democracy & Creating a New Colonial World](https://www.democracynow.org/2025/6/4/karen_hao_empire_of_ai)

Extended interview with Karen Hao, author of Empire of AI: Dreams and Nightmares in Sam Altman’s OpenAI. The book documents the rise of OpenAI and how the AI industry is leading to a new form of colonialism.



**:Model Instructions:** 

**:You:** please summarize this transcript in detail:

**:You:** please repeat your answer using bullet points

---

**:01JR0E39PYK7YKH4FBR4W00CMV::gemini-2.5-flash-preview-04-17:** Here is a detailed summary of the transcript in bullet points:

*   **Introduction of Karen Hao and "Empire of AI":** The transcript begins by introducing journalist Karen Hao and her new book, "Empire of AI: Dreams and Nightmares in Sam Altman’s OpenAI." The book compares the actions of the AI industry, particularly OpenAI, to historical colonial powers.
*   **Critique of AI Industry's Resource Extraction:** Hao argues that AI empires seize and extract valuable resources:
    *   The work and data of artists, writers, and countless individuals online.
    *   The land, energy, and water required for massive data centers and supercomputers.
    *   While not involving overt violence like past colonialism, this extraction causes significant social, labor, and environmental harms.
*   **Political Context: Blocking State AI Regulation:** The discussion highlights a provision in a recent House-passed budget bill that would prohibit any state-level regulation of AI for the next decade, seen as a significant benefit to the AI industry.
    *   Republican Congresswoman Marjorie Taylor Greene criticized this provision, claiming she was unaware of it when voting for the bill and opposes it as a violation of state rights.
*   **Explaining AI and the Book's Title:** Hao explains that AI is a collection of technologies, most commonly known through ChatGPT. "Empire of AI" critiques Silicon Valley's "scale-at-all-costs" approach to AI development.
    *   This approach involves training models on enormous amounts of data (like the full English internet) and using vast supercomputers needing tens to hundreds of thousands of computer chips across areas the size of football fields.
*   **Environmental Impact: Energy and Water Consumption:** Hao details the significant environmental costs:
    *   **Energy:** Based on current expansion, data centers in the next five years could require energy equivalent to 2-6 times California's annual consumption, largely serviced by fossil fuels (extending the life of coal plants, using unlicensed methane turbines).
    *   **Water:** Data centers require clean freshwater, often tapping into public drinking water supplies. Two-thirds of new data centers are being placed in water-scarce areas globally, raising concerns about distribution and access for communities.
*   **Military Aspect of AI:** Silicon Valley companies are increasingly becoming defense contractors.
    *   This is driven by the need to recoup the huge costs of AI development.
    *   Hao finds it alarming that these companies are aggressively pushing technologies not designed for sensitive military contexts into defense infrastructure.
*   **Reporting from the Global South: Case Studies:**
    *   **Chile (Data Centers & Water):** Google proposed a data center near Santiago that would use a thousand times more public freshwater annually than the local community, seemingly without paying local taxes or providing direct community benefits. Activists organized resistance, blocking the project for years and gaining a seat at roundtables with the government and Google to discuss more beneficial data center development.
    *   **Kenya (Data Annotation Labor):** Data annotation firms hire contract labor in countries like Kenya to clean and annotate data for AI training. OpenAI contracted these firms for content moderation, requiring Kenyan workers to read through extremely harmful text (worst internet content and AI-generated hate speech) to train safety filters. These workers are paid minimally, suffer severe psychological trauma, highlighting the exploitative labor practices underpinning the industry.
*   **Sam Altman and the Founding of OpenAI:**
    *   Altman is a product of Silicon Valley's culture, strategic and good at storytelling.
    *   He identified AI early and strategically positioned himself.
    *   OpenAI was initially founded as a nonprofit "to ensure artificial general intelligence benefits all of humanity," partly inspired by the idea that "the best way to build a religion is actually to build a company."
    *   They shifted to the "scale-at-all-costs" approach, realizing capital was the bottleneck.
    *   Altman, a skilled fundraiser, created a for-profit arm within the nonprofit to raise billions, making OpenAI highly capitalistic despite its initial mission.
*   **The Controversial Budget Bill & Altman's Lobbying:** The provision blocking state AI regulation is seen as codifying Silicon Valley's impunity.
    *   Hao links it to Altman's shifting lobbying tactics: initially welcoming *future* regulation based on hypothetical dangers, then advocating for a "light-touch" federal approach and opposing complex state regulations.
    *   Senators supporting the bill echo Altman's sentiments about needing a light touch and avoiding 50 different state environments.
    *   Hao stresses the severity of preventing state regulation of a fast-moving technology for a decade.
*   **Potential State Regulation: Jobs and Labor:** States could regulate AI's impact on jobs.
    *   AI is causing layoffs not necessarily because it fully replaces workers, but because it's *perceived* as capable enough by executives.
    *   Hao contrasts labor-automating AI (OpenAI's goal) with labor-assistive AI (tools helping humans, like doctors or teachers, leading to better outcomes).
    *   Companies design technology to automate jobs to sell services for cost reduction (citing "Power and Progress").
    *   Altman's statements about AI replacing lawyers illustrate the trend of breaking career ladders and making it hard for new graduates to find entry-level jobs.
*   **The "Quasi-Religious Movements" of AGI:** Hao describes factions within Silicon Valley based on belief in Artificial General Intelligence (AGI), which she calls "quasi-religious" because it's not scientifically grounded but based on belief (e.g., human intelligence is fully computational).
    *   **Boomers:** Believe AGI will bring utopia.
    *   **Doomers:** Believe AGI will destroy humanity (by rapidly evolving into a superior species through perfect communication).
    *   Both factions believe AGI is possible and imminent, justifying their desire to control the technology. Hao notes their explanations for *how* these outcomes occur often lack logical detail.
*   **Sam Altman's Ouster and Return:** Altman was briefly fired by the OpenAI board (more Doomer-leaning) due to loss of trust, clashing Boomer/Doomer views on development speed, and inconsistencies around ownership.
    *   He was reinstated because he was the "linchpin" for the company's financial access (Microsoft deal, tender offer, investors) and fear of the company collapsing in the AI talent war.
*   **Altman's Strategic Engagement with Government:** Altman proactively politicked to ingratiate himself with potential new administrations.
    *   He orchestrated the "Stargate Project" announcement with Trump, framing private investment (e.g., SoftBank) as a half-trillion-dollar US project, securing access to resources and protection from rivals like Elon Musk.
    *   His trip to the Middle East led to a data center deal, driven by OpenAI's need for land/energy beyond US constraints.
*   **OpenAI's Global Ambitions and Hypocrisy:** OpenAI's "OpenAI for Countries" program aims to install their tech globally as "democratic AI rails" to counter Chinese "authoritarian AI."
    *   Hao argues this is hypocritical, calling companies like OpenAI "techno-authoritarians" who lack public input and often build data centers secretly under shell companies (Meta's Greater Kudu LLC, Musk's Colossus in Memphis using unlicensed methane turbines polluting the community).
*   **Energy Solutions and Nuclear Power:** Altman advocates for natural gas and future nuclear fission/fusion to meet AI's high energy demands, pushing for unwinding nuclear regulations.
    *   Hao notes that data centers need 24/7 power, making current renewables alone insufficient without better storage, which is why nuclear is pushed.
*   **US vs. China AI Competition:** The US and China are major AI hubs. The US uses export controls (on chips) to limit China's progress.
    *   However, this has led to Chinese talent innovating under constraints.
    *   Companies like High-Flyer (DeepSeek model) achieved similar capabilities to US models with vastly less computational resources (energy, data, chips), proving "scale-at-all-costs" is not the only path. This was enabled by the growing concentration of top AI talent in China.
*   **Impact of US Attacks on Academia:** Trump's "China Initiative" and potential bans on international students alienate crucial talent.
    *   Many Chinese researchers, who once aspired to work in the US, are now choosing to stay or return to China, contributing to the Chinese AI ecosystem and its ability to innovate around US restrictions (like DeepSeek).
    *   This represents a "brain drain" for the US and "brain gain" for other countries, mirroring historical mistakes (like the treatment of Qian Xuesen).
*   **Lack of Diversity in AI:** The AI universe is highly undiverse (mostly men, few Black researchers, privileged backgrounds).
    *   Hao suggests this insular, homogenous environment might contribute to their belief in a fundamentally computational world.
*   **Models of Democratic AI Governance:** No country is fully achieving democratic AI development. The EU AI Act is a step towards risk/rights-based deployment governance.
    *   Hao advocates for democratically *developing* AI, recognizing collectively owned resources (data, land, water, schools, hospitals) as sites for democratic contestation against corporate extraction.
*   **The Te Hiku Media Example (New Zealand):** A positive model of democratic AI development by a Māori couple using AI for language revival.
    *   They consulted their community, gained informed consent for data donation, and used a small, curated data set (couple hundred hours) to build a high-performance speech recognition model, proving that massive scale isn't necessary. This tool is open-sourced for their community.
*   **Vision for the Future of AI:** Hao's vision is for more small, task-specific AI models trained on curated data, requiring less computation, focused on tackling specific societal challenges (climate, healthcare, drug discovery - like AlphaFold or MRI cancer detection) rather than generalized "everything machines."
*   **The Most Shocking Realization:** Writing the book, Hao was most shocked by the "horizontal harm" across all communities she reported on – the initial feeling of a complete loss of agency and ability to self-determine their future when facing the AI empire.
    *   She concludes that AI's current trajectory is threatening democracy by eroding this sense of agency globally.
*   **The Resistance:** Despite the initial feeling of lost agency, communities *are* resisting (artists suing, Chilean activists fighting, Kenyan workers unionizing).
    *   Hao found it heartening that even vulnerable communities remember and seize their agency, which she sees as the first step to reclaiming democracy.
*   **Conclusion:** Amy Goodman thanks Karen Hao for her book and reporting.

